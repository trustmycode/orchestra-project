# Orchestra – Architecture Decision Records (v3)

Этот документ фиксирует ключевые архитектурные решения для целевой версии Orchestra. Все ADR самодостаточны и не опираются на предыдущие версии.

## ADR-0001: Домен независим от протоколов (Channel-Agnostic Domain)

**Статус:** Accepted
**Дата:** 2025-11-14

### Контекст

Система должна тестировать бизнес-процессы, в которых участвуют HTTP, Kafka, gRPC, базы данных и очереди. На уровне домена важны шаги процесса и их побочные эффекты, а не детали транспорта.

### Решение

- Ядро доменной модели (Process, ProcessVersion, ScenarioSuite, TestScenario, ScenarioStep, TestRun, TestRunReport) не содержит жёстких зависимостей от конкретных протоколов.
- Для описания транспорта используются абстракции:
  - `ChannelType` (HTTP_REST, KAFKA, GRPC, DB, QUEUE).
  - `EndpointRef` (protocolId, serviceName, endpointName).
  - `ActionDefinition`, `StepExpectations`, `StepResult`.

### Альтернативы

1. Зашить HTTP/OpenAPI в домен и позже адаптировать под Kafka/gRPC.
2. Делать отдельные движки и модели под каждый протокол.

### Причины выбора

- Требования домена — тестировать процессы и побочные эффекты, а не отдельные HTTP-эндпоинты.
- Возможность комбинировать шаги разных типов в одном сценарии.
- Расширяемость: новый протокол = новый плагин, а не новая доменная модель.

### Последствия

Плюсы:

- Гибкая и расширяемая архитектура.
- Домен «говорит» языком бизнеса («шаг процесса», «проверка побочного эффекта»).

Минусы:

- Усложнение проектирования SPI.
- Нужна аккуратная нормализация ActionResult/Violations.

### Реализация в рамках хакатона

- Домен и SPI реализуются полностью.
- Полный протокол — HTTP/OpenAPI.
- Kafka/gRPC — интерфейсы и скелеты.

---

## ADR-0002: Плагинная модель протоколов (ProtocolPlugin)

**Статус:** Accepted
**Дата:** 2025-11-14

### Контекст

Нужно поддерживать разные протоколы и спецификации без изменения базовой логики Execution Engine.

### Решение

Вводится интерфейс `ProtocolPlugin` со следующими компонентами:

- `ProtocolSpecParser` — парсер спецификаций протокола.
- `EndpointMatcher` — маппинг шагов процессов на эндпоинты/топики/методы.
- `StepExecutor` — выполнение шага сценария.
- `ContractValidator` — валидация ответа/события по контракту.

Создаётся `ProtocolRegistry` (id → ProtocolPlugin).

### Альтернативы

1. Один «комбайн» с `switch(protocolId)` внутри ядра.
2. Отдельные микросервисы под каждый протокол.

### Причины выбора

- OCP: добавление протоколов без изменения существующего кода домена.
- Отделение ответственности: парсинг, маппинг, выполнение, валидация.

### Последствия

Плюсы:

- Расширяемость и независимое развитие плагинов.
- Тестируемость каждого плагина отдельно.

Минусы:

- Требуется управление жизненным циклом плагинов.
- Команде нужно понимать SPI.

### Реализация в рамках хакатона

- `HttpProtocolPlugin` реализуется полностью (OpenAPI, HTTP-вызовы, JSON Schema).
- `KafkaProtocolPlugin` и `GrpcProtocolPlugin` создаются как заготовки (SPI + базовый каркас).

---

## ADR-0003: PostgreSQL + JSONB как основное хранилище

**Статус:** Accepted
**Дата:** 2025-11-14

### Контекст

Структуры шагов, ожиданий, результатов и отчётов эволюционируют. Жёстко нормализованная схема приведёт к постоянным миграциям.

### Решение

- Использовать PostgreSQL как основную БД.
- Хранить гибкие части в jsonb:
  - ProcessVersion.controlFlowGraph.
  - ScenarioStep.action, ScenarioStep.expectations.
  - TestDataSet.data.
  - StepResult payload/violations.
  - TestRunReport.summary/errorsSummary/recommendations.
- Ключевые связи (tenantId, processId, scenarioId, runId, stepId) — реляционные поля с индексами.

### Альтернативы

1. Сильно нормализованная реляционная схема.
2. Отдельная документная БД.

### Последствия

Плюсы:

- Гибкость изменения схем.
- Возможность аналитики SQL + JSONB.

Минусы:

- Сложность индексации JSONB.
- Валидация структуры смещается в приложение.

### Реализация в рамках хакатона

- Создаётся базовая DDL со ссылками + jsonb.
- Управление миграциями через Flyway/Liquibase.
- Минимальные индексы, продвинутая оптимизация — post-MVP.

---

## ADR-0004: SPA Frontend (React + TypeScript)

**Статус:** Accepted
**Дата:** 2025-11-14

### Контекст

Нужен богатый UI для работы с процессами, сценариями, наборами данных и отчётами. Команда знакома с React/TS.

### Решение

- Фронтенд — SPA на React + TypeScript.
- Использовать React Router, TanStack Query.
- State-management (Zustand или Redux Toolkit) при необходимости.
- bpmn-js / mermaid viewer для диаграмм.
- Общение с backend по REST (OpenAPI 3.0).

### Альтернативы

1. Многостраничное серверное приложение.
2. Другие фреймворки (Vue/Angular).

### Последствия

Плюсы:

- Быстрая разработка и богатая экосистема.
- Удобная интеграция визуальных компонентов.

Минусы:

- Отдельный пайплайн сборки frontend.
- SEO не приоритет, но SPA сложнее индексировать (не критично).

### Реализация в рамках хакатона

- Импорт процессов и спецификаций.
- Список сценариев и страница сценария.
- Запуск прогона и просмотр результатов.
- Экран отчёта (минимальный).

---

## ADR-0005: AI как отдельный сервис

**Статус:** Accepted
**Дата:** 2025-11-14

### Контекст

Генерация тестовых данных и аналитика отчётов требуют гибкости: возможна смена AI-провайдера, ключей, лимитов.

### Решение

- Выделить `ai-service` как отдельный сервис/контейнер.
- Orchestra API общается с ним по HTTP/gRPC.
- `ai-service` инкапсулирует интеграцию с LLM, промпты, пост-обработку.

### Альтернативы

1. Встраивать AI-логику в orchestra-api.
2. Выносить AI в отдельный продукт с собственной БД и UI.

### Последствия

Плюсы:

- Независимое масштабирование AI.
- Возможность менять провайдера без затрагивания ядра.

Минусы:

- Дополнительное сетевое взаимодействие и мониторинг.

### Реализация в рамках хакатона

- Допустима упрощённая/заглушечная реализация `ai-service`.
- Должен быть вызов генерации данных и блок «Рекомендации» в отчёте (даже упрощённый).

---

## ADR-0006: Execution Engine через очередь задач и воркеры

**Статус:** Accepted
**Дата:** 2025-11-14

### Контекст

Требуется масштабируемый и отказоустойчивый механизм исполнения сценариев, интегрируемый с CI/CD и не зависящий от одного инстанса.

### Решение

- `POST /testruns` создаёт TestRun со статусом QUEUED и публикует задачу в `run_jobs` (БД или MQ).
- `orchestra-executor` подписывается на очередь, берёт задачу, ставит TestRun в IN_PROGRESS, выполняет шаги и записывает StepResult.
- После завершения обновляет статус TestRun и `finishedAt`.

### Альтернативы

1. Синхронное выполнение сценариев в HTTP-запросе.
2. Периодический опрос БД на наличие PENDING-прогонов.

### Последствия

Плюсы:

- Горизонтальное масштабирование воркеров.
- Восстановление после падений: задания остаются в очереди.

Минусы:

- Дополнительная инфраструктура (MQ).
- Сложность отладки распределённого Execution Engine.

### Реализация в рамках хакатона

- Допустимо хранить очередь в БД, но интерфейсы остаются теми же.
- Один воркер, демонстрирующий концепцию.

---

## ADR-0007: Side-Effect Assertions как отдельные шаги сценария

**Статус:** Accepted
**Дата:** 2025-11-14

### Контекст

Нужно проверять побочные эффекты (БД, Kafka, очереди). Возможные подходы: встраивать проверки в ACTION, делать отдельный watcher, или выделить ASSERTION-шаги.

### Решение

- Вводится `StepKind` с вариантами ACTION и ASSERTION.
- Расширяется `ChannelType` на DB, QUEUE, KAFKA.
- DB/Kafka/Queue ASSERT реализуются как отдельные `ScenarioStep` в сценарии с собственными статусами и нарушениями.

### Альтернативы

1. Прятать ASSERTION внутри ACTION.
2. Делать фоновый watcher по логам/мониторингу.

### Последствия

Плюсы:

- Сценарии читаемы: «создали заказ → проверили БД → проверили Kafka → проверили очередь».
- Единый Execution Engine для всех типов проверок.

Минусы:

- Количество шагов растёт.
- Нужно управлять нагрузкой polling-запросов.

### Реализация в рамках хакатона

- Хотя бы один DB ASSERT и один Kafka/Queue ASSERT (скелет).

---

## ADR-0008: Модель окружений и коннекторов к SUT

**Статус:** Accepted
**Дата:** 2025-11-14

### Контекст

Сценарии должны запускаться против разных стендов (dev/qa/stage). В meta шагов используются alias’ы dataSource, clusterAlias, brokerAlias.

### Решение

- Вводятся `DbConnectionProfile`, `KafkaClusterProfile`, `QueueBrokerProfile`.
- Вводится `Environment`, который маппит alias → профиль.
- В шагах сценария хранятся только alias, секреты лежат во внешнем Secret Manager.

### Альтернативы

1. Хранить полноценные DSN в каждом шаге.
2. Делать отдельные сценарии под каждое окружение.

### Последствия

Плюсы:

- Лёгкое переключение окружений.
- Централизованное управление коннекторами SUT.

Минусы:

- Дополнительные сущности и UI для настройки окружений.

### Реализация в рамках хакатона

- Минимум: alias + профиль для БД.
- UI для Environment может быть упрощённым.

---

## ADR-0009: Consistency и flakiness ASSERTION-шагов

**Статус:** Accepted
**Дата:** 2025-11-14

### Контекст

Побочные эффекты проявляются не сразу (eventual consistency). Тесты не должны быть случайно красными.

### Решение

1. ASSERTION-шаги имеют `timeoutMs` и `pollIntervalMs`.
2. При отсутствии успеха до `timeoutMs`:
   - создаётся нарушение `TIMEOUT` + специфичный тип (DB_ASSERTION_FAILED, KAFKA_MESSAGE_NOT_FOUND, QUEUE_MESSAGE_NOT_FOUND);
   - шаг помечается FAILED.
3. Post-MVP: конфигурируемые повторы и статус FLAKY, если успех достигнут со второй/третьей попытки.
4. Отчёт явно показывает таймауты и flakiness, собираются метрики.

### Альтернативы

- Не использовать polling (проверка один раз).
- Использовать слишком большие таймауты.

### Последствия

- ASSERTION шаги добавляют нагрузку на SUT (повторные SELECT/poll).
- Нужен глобальный предел времени TestRun.
- Требуется мониторинг частоты TIMEOUT/FLAKY.

---

## ADR-0010: Моделирование сложных процессов через ScenarioSuite и линейные сценарии

**Статус:** Accepted
**Дата:** 2025-11-14

### Контекст

BPMN-процессы содержат ветвления, параллельные ветки и циклы. Полноценный BPMN-движок усложнит систему, но тесты должны быть детерминированными и читаемыми.

### Решение

- Вводится `ScenarioSuite` — набор сценариев, покрывающих процесс.
- `ProcessToScenarioGenerator` строит граф управления потоком и генерирует набор линейных путей (сценариев), покрывающих ветвления, параллельные комбинации и ограниченные итерации циклов.
- Execution Engine работает с линейными `TestScenario`.

### Альтернативы

1. Выполнять BPMN «как есть» (встроенный BPMN-движок).
2. Игнорировать ветвления/параллельность.

### Последствия

Плюсы:

- Сохраняется простота Execution Engine.
- Сценарии читаемы и пригодны для ревью.

Минусы:

- Не все пути покрываются автоматически (но генератор можно расширять).

### Реализация в рамках хакатона

- Минимум один линейный сценарий на процесс.
- Заготовка для ProcessToScenarioGenerator.

---

## ADR-0011: TestDataSet и параметризация сценариев

**Статус:** Accepted
**Дата:** 2025-11-14

### Контекст

Жёстко зашитые данные делают тесты хрупкими и мешают покрывать разные классы входов.

### Решение

- Вводится `TestDataSet` как отдельная сущность.
- Шаги сценария используют плейсхолдеры `{{data.*}}` и `{{step.alias.response.*}}`.
- При запуске ExecutionContext.variables["data"] = TestDataSet.data.
- AI-сервис может генерировать/обновлять наборы данных.

### Альтернативы

1. Хранить данные прямо внутри `ScenarioStep.action.inputTemplate`.
2. Передавать данные целиком в TestRunCreateRequest без сохранения.

### Последствия

Плюсы:

- Повторное использование наборов данных.
- Разделение «что тестируем» и «на каких данных».

Минусы:

- Дополнительный уровень сущностей и UI.

---

## ADR-0012: RBAC и мультиарендность

**Статус:** Accepted
**Дата:** 2025-11-14

### Контекст

Orchestra используется разными командами/клиентами. Нельзя допускать утечек и конфликтов конфигураций.

### Решение

- Вводится `Tenant`, все ключевые сущности имеют `tenantId`.
- Модель ролей: ORG_ADMIN, TEST_DESIGNER, TEST_RUNNER, VIEWER.
- Авторизация: JWT с tenantId и roles, проверки на уровне приложения и (при необходимости) политики БД (RLS).

### Альтернативы

1. Single-tenant дизайн с логической изоляцией только на уровне UI.
2. Физически отдельная БД на каждого клиента.

### Последствия

Плюсы:

- Безопасное разделение данных между клиентами.
- Масштабируемость за счёт добавления новых tenant’ов.

Минусы:

- Усложнение схемы БД.
- Сложные миграции/операции (учитывать tenantId).

---

## ADR-0013: Версионирование артефактов и история изменений

**Статус:** Accepted
**Дата:** 2025-11-14

### Контекст

Процессы, спецификации и сценарии эволюционируют. Нужно понимать, с какой версией сценария запускался прогон и кто что менял.

### Решение

- ProcessVersion, TestScenario.version, ProtocolSpec.version.
- Изменение сценария → новая версия (copy-on-write); старая помечается DEPRECATED или остаётся PUBLISHED.
- TestRun хранит ссылку на конкретную версию сценария.
- Audit_log фиксирует события (create/update/delete, пользователь, timestamp).

### Альтернативы

1. Изменять сценарии «на месте» без версий.
2. Хранить историю только в Git.

### Последствия

Плюсы:

- Воспроизводимость прогонов.
- Возможность отката к предыдущим версиям.

Минусы:

- Рост объёма хранимых данных.
- Требуется продуманный UX версионирования.

---

## ADR-0014: Политика хранения и архивации данных

**Статус:** Accepted
**Дата:** 2025-11-14

### Контекст

Результаты тестов и отчёты быстро растут и влияют на производительность и стоимость хранения.

### Решение

- Пер-tenant политика ретеншн (по умолчанию, например, 90 дней для TestRun/TestStepResult).
- Фоновые задачи `cleanup_old_runs` удаляют/архивируют старые записи; опционально — архивирование в объектное хранилище.
- Настройки конфигурируемы для крупных клиентов.

### Альтернативы

1. Не удалять данные вообще.
2. Сразу писать отчёты только в объектное хранилище.

### Последствия

Плюсы:

- Контролируемый рост БД.
- Возможность долгосрочного хранения отчётов в архиве.

Минусы:

- Дополнительный код обслуживания.
- Нужно документировать сроки хранения.

---

## ADR-0015: MVP Scope для хакатона

**Статус:** Accepted
**Дата:** 2025-11-14

### Контекст

Хакатон ограничен по времени, требуется компромисс между полнотой архитектуры и реалистичным объёмом реализации.

### Решение (MVP Scope)

1. **Протоколы** — полный HTTP/OpenAPI плагин; Kafka/DB ASSERTION (скелеты).
2. **Диаграммы** — импорт BPMN и простых sequence-диаграмм.
3. **Сценарии** — линейные сценарии без ветвлений/циклов в Execution Engine.
4. **Execution Engine** — простая очередь задач (можно через БД), один воркер.
5. **AI** — генерация тестовых данных для HTTP (HAPPY_PATH), базовые рекомендации.
6. **UI** — импорт процессов/спек, конструктор шагов, запуск прогона, просмотр результатов и отчёта.

### Последствия

- Архитектура строится под full-scope (v4).
- MVP демонстрирует ядро «оркестра тестов бизнес-процессов».
- Дальнейшее развитие — реализация ADR-0006–0014 без перестройки архитектуры.

---

## ADR-0018: Использование Retrieval-Augmented Generation (RAG) для контекстно-зависимой генерации тестовых данных

**Статус:** Accepted
**Дата:** 2024-07-30

### Контекст

Простая генерация данных по JSON Schema (ADR-0016) создаёт синтаксически корректные, но семантически изолированные данные. Для тестирования реальных бизнес-процессов необходимо, чтобы генерируемые данные (например, `customerId`, `productId`) были валидными и консистентными в рамках тестовой среды. Ручное предоставление списков значений решает эту проблему, но плохо масштабируется и требует постоянного вмешательства пользователя.

### Решение

1. **Внедрение RAG-пайплайна.** `ai-service` выполняет семантический поиск по базе знаний, извлекает релевантные примеры реальных данных и передаёт их в промпт как контекст перед обращением к LLM.
2. **База знаний.** Используется векторная БД (ChromaDB, Weaviate или PGVector), которая хранит эмбеддинги ключевых сущностей тестовой среды.
3. **Индексатор данных.** Фоновый процесс `Data Indexer` периодически подключается к тестовым БД (определённым в `Environment`), извлекает данные из помеченных таблиц, преобразует их в текстовые описания, строит эмбеддинги и загружает их в векторную БД.

### Альтернативы

1. **Генерация только по схеме.** Не даёт валидных идентификаторов и не поддерживает консистентность — отклонено.
2. **Ручное предоставление списков значений.** Не масштабируется и требует постоянного ручного обновления — отклонено.

### Последствия

Плюсы:

- Генерация данных становится релевантной тестовой среде.
- Минимум ручных настроек, высокая автоматизация.
- Масштабируемость — добавление новых сущностей требует только их индексации.

Минусы:

- Требуются дополнительные компоненты (векторная БД, индексатор).
- Процесс векторизации потребляет ресурсы.
- Решение сложнее в реализации и поддержке.

---

## ADR-0019: Использование паттерна "LLM as Planner + Data Resolvers" для генерации тестовых данных

**Статус:** Accepted
**Дата:** 2024-07-30

### Контекст

`ADR-0018` предлагал использовать RAG для предоставления LLM примеров данных, чтобы она могла генерировать валидные идентификаторы. Однако этот подход не гарантирует, что модель будет использовать предложенный контекст и не решает проблему сложной референциальной целостности, делая процесс генерации нестабильным.

### Решение

Мы переходим к более надежному паттерну **"LLM as Planner + Tools"**.
1. **Разделение ролей:**
   - **`ai-service` (Planner):** LLM генерирует **"план данных" (`DataPlan`)** — структурированный JSON, описывающий *требования* к данным (например, `{"customerCriteria": {"segment": "retail"}}`).
   - **`Data Resolver` (Tool):** Новый компонент внутри `orchestra-api`, который принимает `DataPlan`, преобразует его в детерминированные запросы (SQL) к тестовой БД, извлекает **реальные** данные и собирает финальный JSON.
2. **Использование RAG:** RAG и векторный поиск (с помощью **PGVector**) становятся частью `Data Resolver` и используются для выполнения **семантических** критериев из `DataPlan`.
3. **Явный контракт:** Для связи полей API с сущностями используются кастомные расширения в OpenAPI (например, `x-orchestra-entity: customer`).

### Последствия

**Плюсы:**
- **Детерминизм и надежность:** Финальные данные всегда валидны.
- **Управляемость:** Логика подбора данных находится в тестируемом Java-коде.
- **Упрощение `ai-service`:** Его задача становится более четкой.

**Минусы:**
- **Новый компонент:** Требуется разработка `Data Resolver`.
- **Расширение OpenAPI:** Требуется аннотировать спецификации.

---

## ADR-0020: Durable Workflow Execution Engine

**Статус:** Accepted
**Дата:** 2024-07-30

### Контекст

Простой `Execution Engine` на базе очереди теряет состояние (`ExecutionContext`) при сбое воркера, что делает восстановление невозможным или неэффективным. Также существует риск "зависших" задач и проблем с производительностью из-за блокировок.

### Решение

1. **Durable State:** PostgreSQL становится **единственным источником правды**. Состояние `TestRun`, включая `ExecutionContext` и статусы шагов, персистентно хранится в БД и обновляется транзакционно после каждого шага. Воркеры (`orchestra-executor`) становятся **безсостоятельными (stateless)**.
2. **Lease Pattern:** Вместо `SELECT FOR UPDATE` для захвата задачи используется атомарный `UPDATE ... WHERE status='QUEUED' ... RETURNING *`. Это паттерн "аренды", который избегает жестких блокировок.
3. **Heartbeat & Reaper:** Воркер во время выполнения периодически обновляет поле `heartbeat_at` в `TestRun`. Отдельный фоновый процесс (`Reaper`) находит "зависшие" прогоны (где `heartbeat_at` устарел) и переводит их в статус `FAILED_STUCK`.
4. **Scheduler:** Вводится компонент `Scheduler`, который управляет потоком задач. `TestRun` создается со статусом `PENDING`. `Scheduler` применяет лимиты по тенантам и приоритеты, а затем переводит задачи в `QUEUED` и отправляет в RabbitMQ.

### Последствия

**Плюсы:**
- **Отказоустойчивость:** Сбой воркера не приводит к потере прогресса. Новый воркер может продолжить выполнение с последнего успешного шага.
- **Масштабируемость:** Паттерн аренды и безсостоятельные воркеры отлично масштабируются горизонтально.
- **Управляемость:** `Scheduler` обеспечивает контроль над ресурсами и fairness между тенантами.

**Минусы:**
- **Повышенная нагрузка на БД:** Каждый шаг требует транзакции в БД.
- **Усложнение архитектуры:** Появляются новые компоненты и паттерны (`Scheduler`, `Reaper`, `Lease`).

---

## ADR-0021: Стратегия для параллельного и асинхронного тестирования

**Статус:** Accepted
**Дата:** 2024-07-30

### Контекст

Тестирование BPMN-процессов с `Parallel Gateway` и асинхронными операциями требует специальных подходов для сохранения детерминизма и надежной проверки побочных эффектов.

### Решение

1. **`BARRIER` Step:** Вводится новый тип шага, `BARRIER`. Он используется для синхронизации параллельных веток. `BARRIER` ожидает завершения указанного списка шагов (`trackedSteps`) перед тем, как позволить сценарию продолжиться.
2. **Разделение тестов:**
   - **Функциональные тесты:** `ProcessToScenarioGenerator` по умолчанию создает один "base-scenario" для `Parallel Gateway`, располагая ветки последовательно и завершая их `BARRIER`-шагом.
   - **Конкурентные тесты:** Для `Parallel Gateway`, ветки которого работают с общими ресурсами, генератор дополнительно создает ограниченный набор сценариев с перестановкой порядка выполнения этих веток.
3. **Изоляция через `correlationId`:** Каждый `TestRun` получает уникальный `correlationId`. Все исходящие запросы (HTTP, Kafka) автоматически обогащаются этим ID. `ASSERTION`-шаги используют его для фильтрации, чтобы находить побочные эффекты, относящиеся только к текущему тесту.
4. **Метрики "Settling Time":** `ASSERTION`-шаги с polling'ом измеряют и экспортируют метрику `timeToSuccess`, что позволяет отслеживать производительность и деградацию SUT.

### Последствия

**Плюсы:**
- **Явное управление параллелизмом:** `BARRIER` делает логику ожидания понятной и управляемой.
- **Контролируемое покрытие:** Разделение на функциональные и конкурентные тесты позволяет избежать комбинаторного взрыва, но при этом покрыть риски `race conditions`.
- **Надежность ассертов:** `correlationId` решает проблему "шумного соседа" в асинхронной среде.

**Минусы:**
- Усложнение `Execution Engine` и `ProcessToScenarioGenerator`.

---

## ADR-0022: Оркестрация зависимых сценариев через `SuiteRun`

**Статус:** Accepted
**Дата:** 2024-07-30

### Контекст

Некоторые бизнес-процессы требуют выполнения нескольких сценариев в определенной последовательности (например, "Создать заказ", затем "Отменить заказ"). Также может потребоваться передача данных (например, `orderId`) между этими сценариями.

### Решение

1. **`SuiteRun` Orchestrator:** Вводится логика оркестрации на уровне `SuiteRun`. Простой запуск всех сценариев заменяется на управляемый граф выполнения.
2. **Зависимости по управлению:** В `TestScenario` вводится поле `dependsOn`, где можно указать, после какого сценария (и с каким статусом) должен запускаться текущий.
3. **Зависимости по данным:**
   - В `SuiteRun` добавляется общее хранилище `context (JSONB)`.
   - В `ScenarioStep` добавляется поле `exportAs`, позволяющее экспортировать часть ответа шага в `SuiteRun.context`.
   - Шаги в последующих сценариях могут использовать эти данные через плейсхолдеры `{{suite.*}}`.
4. **Процесс выполнения:** `SuiteRun Orchestrator` (часть `Scheduler`'а) анализирует граф зависимостей, запускает сначала "корневые" сценарии, а затем, по мере их завершения, запускает зависимые, передавая им актуальный `SuiteRun.context`.

### Последствия

**Плюсы:**
- **Сквозное тестирование:** Позволяет моделировать и тестировать полные, сложные жизненные циклы бизнес-сущностей.
- **Переиспользование данных:** Упрощает подготовку данных для зависимых сценариев.

**Минусы:**
- **Усложнение тестов:** Создает сильную связь между сценариями, что может сделать их более хрупкими.
- **Усложнение `SuiteRunService` и `Scheduler`'а:** Требуется реализация графа зависимостей и логики оркестрации.

---

## ADR-0016: Структурированный вывод AI через Spring AI и локальную LLM

**Статус:** Accepted
**Дата:** 2024-07-30

### Контекст

`ADR-0005` закрепил создание `ai-service`, но не определял способ получения гарантированно валидного JSON от LLM. Неструктурированные ответы ведут к хрупкой интеграции и множеству ручных обработок. Требуется стек, который позволит формировать строгие модели данных при генерации тестовых наборов.

### Решение

- `ai-service` реализуется на Spring Boot и использует **Spring AI**.
- Для вызовов LLM применяется `OllamaChatClient` (или совместимые клиенты) с **BeanOutputParser**, который описывает структуру целевого DTO и заставляет модель отдавать валидный JSON.
- Бизнес-DTO: запрос с JSON Schema/контекстом и ответ `GeneratedData` (или расширенные модели) описываются в Java и выступают контрактом между `orchestra-api` и `ai-service`.

### Альтернативы

1. **Парсинг свободного текста** – отправлять инструкции «верни JSON» и вручную разбирать ответ. Отклонено из‑за ненадёжности и высокой стоимости обработки ошибок.
2. **Python/Node сервис с LangChain/LlamaIndex** – отдельный стек и языки разработки. Отклонено, чтобы избежать дублирования квалификации и пайплайнов; Spring AI даёт тот же функционал в существующей Java-экосистеме.

### Последствия

Плюсы:

- Гарантированная «структура» ответа, минимум пост-обработки.
- Конфигурационная смена модели/провайдера без переписывания бизнес-кода.
- Улучшенная наблюдаемость за промптами и результатами внутри одного фреймворка.

Минусы:

- Новая зависимость от Spring AI (версия/совместимость нужно отслеживать).
- Разработчикам нужно освоить подход BeanOutputParser и PromptTemplate.

### Реализация в рамках хакатона

- Создать DTO и сервис генерации поверх Spring AI.
- Обеспечить минимальный контроллер в `ai-service`, принимающий JSON Schema и возвращающий готовые данные.

---

## ADR-0017: Выбор Ollama в качестве рантайма локальных LLM

**Статус:** Accepted
**Дата:** 2024-07-30

### Контекст

Чтобы выполнить ADR-0016, требуется локальный рантайм LLM, совместимый со Spring AI и пригодный для быстрой настройки. Рассматривались разные способы запуска моделей (llama.cpp, LM Studio, headless моды), но нужен вариант, который легко устанавливается, предоставляет стабильный API и не усложняет Java-сервисы.

### Решение

- Основная среда выполнения — **Ollama**.
- Разработчики устанавливают Ollama на локальные машины и скачивают рекомендованную модель (**Mistral 7B Instruct** или **Llama 3 8B Instruct**).
- `ai-service` получает базовый URL через конфигурацию (`OLLAMA_BASE_URL`) и взаимодействует с рантаймом через REST API (совместим с OpenAI).

### Альтернативы

1. **Прямой `llama.cpp` сервер** – максимальный контроль и производительность, но требует ручной сборки/конфигурации. Отклонено из‑за сложности и удлинения time-to-first-LLM.
2. **LM Studio** – удобный GUI, но не предназначен для headless-развёртываний и CI, что не соответствует целям проекта.
3. **Java bindings для `llama.cpp`** – встраивание модели в JVM-процесс. Отклонено, чтобы сохранить разделение ответственности и избежать тяжёлых нативных зависимостей внутри `ai-service`.

### Причины выбора Ollama

- Установка одной командой + `ollama pull mistral`.
- OpenAI-совместимый API, сразу работающий с Spring AI.
- Чёткое разделение: тяжёлый AI-рантайм остаётся вне JVM приложения.
- Возможность перескочить на другой OpenAI-совместимый endpoint простым изменением URL.

### Последствия

- Требуется наличие Ollama у всех разработчиков и на CI-агентах (или отдельный хост).
- `ai-service` зависит от сетевой доступности Ollama (нужны health-check и ретраи).
- Производительность соответствует MVP, но при росте нагрузки можно заменить Ollama на `llama.cpp server` или внешний провайдер без переписывания кода.

---

## ADR-0025: Использование фреймворка `sgr-agent-core` как основы для `ai-service`

**Статус:** Accepted
**Дата:** 2024-07-30

### Контекст

Реализация различных AI-функций (`Data Planner`, `Report Analyst`, `Mapping Assistant`, `Assertion Helper` и т.д.) требует создания сложной логики для многошагового рассуждения, вызова инструментов (tools) и обработки результатов. Разработка уникального решения для каждой функции приведёт к дублированию кода и усложнит поддержку `ai-service`.

### Решение

Для реализации внутренней логики `ai-service` будет использован open-source фреймворк **`sgr-agent-core`** в качестве **единой, стандартной платформы**. Каждая интеллектуальная функция формулируется как цель для агента, а доступ к данным и системам осуществляется через набор предоставленных ему «инструментов» (простые Java-методы). `sgr-agent-core` управляет циклами рассуждения, вызовами инструментов и рефлексией, а также интегрируется со Spring AI.

### Альтернативы

1. **Ручная реализация под каждую функцию:** Самостоятельно писать промпты, вызывать LLM и парсить ответы. **Отклонено:** высокая стоимость поддержки и риск расхождений между реализациями.
2. **Использование Spring AI напрямую:** Spring AI даёт низкоуровневые блоки (клиенты, парсеры), но не обеспечивает готовый агентский цикл. `sgr-agent-core` предоставляет более высокую абстракцию и может использовать Spring AI «под капотом».

### Последствия

**Плюсы:**
- **Унифицированный подход:** все AI-функции реализуются как «агенты + инструменты», что упрощает поддержку и масштабирование.
- **Ускорение разработки:** повторно используем общий стек и инфраструктуру для всех интеллектуальных возможностей.
- **Повышение надёжности:** фреймворк инкапсулирует практики рассуждения, обработку ошибок и рефлексию.
- **Тестируемость:** логика декомпозируется на небольшие Java-инструменты, которые легко покрывать тестами.

**Минусы:**
- **Новая зависимость:** проект начинает зависеть от внешнего open-source фреймворка.
- **Порог вхождения:** команде нужно изучить API и концепции `sgr-agent-core`.
---

## ADR-0026: Создание общего модуля `orchestra-domain`

**Статус:** Accepted
**Дата:** 2024-07-30

### Контекст

Архитектура сервера включает как минимум два независимых Spring Boot приложения (`orchestra-api` и `orchestra-executor`), которые работают с одной и той же базой данных PostgreSQL. Оба сервиса должны иметь единый доступ к доменной модели: JPA-сущностям, Spring Data репозиториям, DTO и мапперам. До принятия решения весь этот код хранился внутри `orchestra-api`, что вынуждало либо дублировать его в других сервисах, либо напрямую зависеть от исполняемого артефакта API.

### Решение

Создать отдельный модуль-библиотеку **`orchestra-domain`**, который компилируется в `.jar` и подключается как зависимость в `pom.xml` сервисов. Модуль содержит:

1. Все JPA-сущности (`@Entity`).
2. Все Spring Data репозитории (`@Repository`).
3. Общие DTO и мапперы.

Сервисы `orchestra-api` и `orchestra-executor` подключают `orchestra-domain` как зависимость, получая общий слой доступа к данным без дублирования.

### Альтернативы

1. **Дублирование кода** в каждом сервисе. Отклонено из-за постоянного риска рассинхронизации при изменениях в доменной модели.
2. **Выделение отдельного Data Access Service**, к которому остальные сервисы обращались бы по HTTP/gRPC. Отклонено: усложняет архитектуру, добавляет сетевые задержки и усложняет транзакционные сценарии.

### Последствия

Плюсы:

- Единый источник правды для доменной модели.
- Следование принципу DRY и упрощение сопровождения.
- Уменьшение порога входа для новых сервисов, которые могут переиспользовать доменную модель.

Минусы:

- Появляется зависимость на уровне сборки: изменение `orchestra-domain` требует пересборки сервисов, которые от него зависят. Для тесно связанных сервисов это приемлемо.
---

## ADR-0027: Централизованный `Scheduler` для управления задачами

**Статус:** Accepted
**Дата:** 2024-07-30

### Контекст

В мультиарендной среде необходимо управлять потоком тестовых прогонов, чтобы обеспечивать справедливость использования ресурсов и приоритизацию. Немедленная отправка каждой задачи в RabbitMQ не решает эти проблемы и создает риск «шумного соседа».

### Решение

1. **`Scheduler` как единственная точка принятия решений:** Отдельный компонент `Scheduler` отвечает за перевод `TestRun` и `SuiteRun` из `PENDING` в `QUEUED`.
2. **Размещение:** `Scheduler` реализован как фоновый `@Scheduled`-процесс внутри `orchestra-api`.
3. **Новый статус `PENDING`:** Прогоны создаются в `PENDING` и остаются там до решения `Scheduler`.
4. **Логика:** Периодическое сканирование `PENDING` задач, применение квот по `tenant_settings`, учет приоритетов (UI vs CI) и зависимостей `SuiteRun`. Только готовые задачи переводятся в `QUEUED` и публикуются в RabbitMQ.

### Альтернативы

1. **Децентрализованный контроль в воркерах.** Отклонено: усложняет глобальное управление лимитами и fairness.
2. **Сложные политики маршрутизации RabbitMQ.** Отклонено: бизнес-логика уходит в инфраструктуру и становится неявной.

### Последствия

**Плюсы:**
- Централизованная точка контроля за ресурсами.
- Простота расширения политик планирования и приоритетов.
- Защита платформы от перегрузок и всплесков.

**Минусы:**
- Дополнительная сложность и ответственность в `orchestra-api`.
- Требуются новые метрики и алерты на задержки планирования.

---

## ADR-0028: Паттерн `Tenant Context Propagation` для изоляции данных

**Статус:** Accepted
**Дата:** 2024-07-30

### Контекст

Для строгой изоляции данных (см. `ADR-0012`) нужно гарантировать, что `tenant_id` текущего запроса корректно передается от API до уровня БД и RLS-политик без ручной прокидки через параметры всех слоев.

### Решение

1. **`OncePerRequestFilter`:** На входе в `orchestra-api` извлекает `tenant_id` из JWT и сохраняет его в `TenantContextHolder` (`ThreadLocal`).
2. **`TenantContextHolder`:** Предоставляет статический API (`getCurrentTenantId`) для сервисов и репозиториев.
3. **`Transaction Synchronization` / `Hibernate Interceptor`:** Перед каждой транзакцией читает `tenant_id` и выполняет `SET LOCAL app.current_tenant = '...'`, активируя RLS.
4. **JPA-репозитории:** Используют `TenantContextHolder` для явного добавления `WHERE tenant_id = ...` в запросы и использования индексов.
5. **Очистка:** В `finally` блоке фильтра `TenantContextHolder` очищается, исключая утечки контекста между запросами.

### Последствия

**Плюсы:**
- Автоматическая и безопасная передача `tenant_id` сквозь приложение.
- Снижение количества явных параметров в API и сервисах.
- Гарантия корректной работы RLS и индексов.

**Минусы:**
- Повышенные требования к тестированию многопоточности.
- Необходимо следить за отсутствием блокирующих операций внутри `ThreadLocal`-зависимой логики.

---

## ADR-0029: Поддержка PlantUML (Sequence Diagrams) как источника сценариев

**Статус:** Accepted
**Дата:** 2024-07-30

### Контекст

BPMN покрывает сценарии аналитиков, но разработчики часто описывают взаимодействия сервисов через sequence-диаграммы (PlantUML/Mermaid). Отсутствие поддержки этих форматов ограничивает разработчиков, практикующих «diagrams as code», и усложняет импорта интеграционных сценариев.

### Решение

1. **Расширение источников:** Добавить импорт `.puml` файлов PlantUML.
2. **Унифицированная модель:** Использовать `ProcessVersion.controlFlowGraph` (JSONB) как универсальный слой между исходным форматом (BPMN/PUML) и генератором сценариев.
3. **Конвертер:** Реализовать преобразование семантики sequence-диаграммы в control-flow graph:
   - Сообщения (`->`) → узлы действия (`ACTION`).
   - Блоки `alt/opt` → ветвления `Exclusive Gateway`.
   - Блоки `par` → параллельные ветки (`Parallel Gateway`).
   - Блоки `loop` → циклы в графе.
4. **Прозрачная генерация:** `ProcessToScenarioGenerator` работает с графом и не зависит от источника.

### Последствия

**Плюсы:**
- Более широкая аудитория: разработчики могут описывать процессы в текстовом формате PlantUML.
- Sequence-диаграммы детально показывают взаимодействия HTTP/async и подходят для интеграционных сценариев.

**Минусы:**
- Более сложный парсинг и необходимость ограничения поддерживаемых конструкций на первом этапе.
- Возможная потеря специфической семантики (например, время жизни объектов) при преобразовании в универсальный граф.

---

## ADR-0030: Модернизация фронтенда (React + Tailwind + Shadcn/ui)

**Статус:** Accepted
**Дата:** 2024-07-30

### Контекст

Текущий фронтенд — MVP на базовых HTML-компонентах со статическими стилями. Он ограничивает расширение UI (мастера, карточки AI, дашборды), не поддерживает полноценную темную тему и затрудняет единообразие UX.

### Решение

1. **UI Kit:** Принять стек **Tailwind CSS + Shadcn/ui (Radix UI)** для всех новых и мигрируемых компонентов.
2. **Роутинг:** Перевести приложение на **React Router DOM v6** с единым layout и nested routes.
3. **Визуализация диаграмм:** 
   - BPMN → `bpmn-js` с адаптацией стилей под темную тему.
   - Sequence/PlantUML → выделенный `plantuml-server` (Jetty), который рендерит SVG по запросу SPA.

### Последствия

**Плюсы:**
- Единый современный дизайн, готовые компоненты и поддержка a11y.
- Нативная поддержка темной темы и визуального консистентного UI.
- Возможность рендерить sequence-диаграммы «на лету».

**Минусы:**
- Существенная миграция существующих экранов.
- Дополнительный сервис `plantuml-server`, требующий поддержки в окружениях.
